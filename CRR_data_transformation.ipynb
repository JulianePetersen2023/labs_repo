{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2746df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ea60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system preparation\n",
    "def file_system_preparation():\n",
    "    '''\n",
    "    Create directories.\n",
    "    Create logfile name.\n",
    "    '''\n",
    "    if not os.path.exists('tables'):\n",
    "        os.makedirs('tables')\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "        \n",
    "    timestamp = '{:%Y-%m-%d_%H-%M}'.format(dt.datetime.now())\n",
    "    logfile_name = f'transformation_{timestamp}'\n",
    "    return logfile_name\n",
    "\n",
    "logfile_name = file_system_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d20f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import table\n",
    "def import_table():\n",
    "    '''\n",
    "    Import Excel file.\n",
    "    Import data.\n",
    "    Import pre-defined lists (sheet 2).\n",
    "    Write to log.\n",
    "    '''\n",
    "    df = pd.read_excel('CRR_data_2024.xlsx')\n",
    "    predefined_lists = pd.read_excel('CRR_data_2024.xlsx', 'structure')\n",
    "    \n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'IMPORT: Data imported. {len(df)} entries.\\n')\n",
    "    \n",
    "    return df, predefined_lists\n",
    "\n",
    "df, predefined_lists = import_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456e6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "#df.isna().sum()\n",
    "#df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cf184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "#df.head()\n",
    "#df.tail()\n",
    "#df.columns\n",
    "#df.shape\n",
    "#df.dtypes\n",
    "#df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670db043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOCH EINFÜGEN: KURZE STATISTIK ZU MISSING VALUES, GGF. DUPLICATES\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NOCH EINFÜGEN: KURZE STATISTIK ZU MISSING VALUES, GGF. DUPLICATES\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d3ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def initial_cleaning(df, predefined_lists):\n",
    "    '''\n",
    "    Remove leading and trailing whitespace from all column names and entries\n",
    "    '''\n",
    "    df.columns = [x.strip() for x in list(df.columns)]\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    predefined_lists.columns = [x.strip() for x in list(predefined_lists.columns)]\n",
    "    predefined_lists = predefined_lists.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write('\\nDATA CLEANING: Whitespace removal successful.\\n')\n",
    "    \n",
    "    return df, predefined_lists\n",
    "\n",
    "df, predefined_lists = initial_cleaning(df, predefined_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357dca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: resource\n",
    "def create_resource_table(df):\n",
    "    resource = df[['No.', 'Name', 'Description', 'Website']]\n",
    "    resource.columns = ['resourceID', 'name', 'description', 'website']\n",
    "    \n",
    "    resource.to_csv('tables/resource.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource.csv created. {len(resource)} entries.\\n')\n",
    "    \n",
    "    return resource\n",
    "\n",
    "resource = create_resource_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46b5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: organisation\n",
    "def create_organisation_table(df):\n",
    "    organisation = df['Organisation'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    organisation = organisation.explode(';')\n",
    "    organisation = organisation.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    organisation.drop_duplicates(inplace=True)\n",
    "    organisation = organisation.sort_values(ascending=True).reset_index(drop=True)\n",
    "    organisation = pd.DataFrame({\n",
    "                   'organisationID': [x for x in range(1,len(organisation)+1)],\n",
    "                   'organisation': organisation\n",
    "                   })\n",
    "    organisation = organisation.dropna(subset=['organisation']).reset_index(drop=True)\n",
    "    organisation.to_csv('tables/organisation.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: organisation.csv created. {len(organisation)} entries.\\n')\n",
    "\n",
    "    df['Organisation']=df['Organisation'].apply(lambda x: x if isinstance(x, str) else '')                    \n",
    "        \n",
    "    if len([x for x in df['Organisation'] if re.match('.*,.*', x)])>=1:\n",
    "        organisation_comma_sep = df[df['Organisation'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Organisation\" entries with \",\" separator (NOT split): {len(organisation_comma_sep)}')\n",
    "            log.write(f'\\n{organisation_comma_sep[[\"No.\", \"Organisation\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Organisation'] if re.match('.*;.*', x)])>=1:\n",
    "        organisation_semicolon_sep = df[df['Organisation'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Organisation\" entries with \";\" separator (split): {len(organisation_semicolon_sep)}')\n",
    "            log.write(f'\\n{organisation_semicolon_sep[[\"No.\", \"Organisation\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Organisation'] if re.match('.*&.*', x)])>=1:\n",
    "        organisation_and_sep = df[df['Organisation'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Organisation\" entries with \"&\" separator (NOT split): {len(organisation_and_sep)}')\n",
    "            log.write(f'\\n{organisation_and_sep[[\"No.\", \"Organisation\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "            \n",
    "    return organisation\n",
    "\n",
    "organisation = create_organisation_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc1da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: country\n",
    "def create_country_table(df):\n",
    "    country = df['Country'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "    country = country.explode(',')\n",
    "    country = df['Country'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    country = country.explode(';')\n",
    "    country = country.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    country.drop_duplicates(inplace=True)\n",
    "    country = country.sort_values(ascending=True).reset_index(drop=True)\n",
    "    country = pd.DataFrame({\n",
    "              'countryID': [x for x in range(1,len(country)+1)],\n",
    "              'country': country\n",
    "              })\n",
    "    country = country.dropna(subset=['country']).reset_index(drop=True)\n",
    "    country.to_csv('tables/country.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: country.csv created. {len(country)} entries.\\n')\n",
    "\n",
    "    df['Country']=df['Country'].apply(lambda x: x if isinstance(x, str) else '')                    \n",
    "        \n",
    "    if len([x for x in df['Country'] if re.match('.*,.*', x)])>=1:\n",
    "        country_comma_sep = df[df['Country'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Country\" entries with \",\" separator (split): {len(country_comma_sep)}')\n",
    "            log.write(f'\\n{country_comma_sep[[\"No.\", \"Country\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Country'] if re.match('.*;.*', x)])>=1:\n",
    "        country_semicolon_sep = df[df['Country'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Country\" entries with \";\" separator (split): {len(country_semicolon_sep)}')\n",
    "            log.write(f'\\n{country_semicolon_sep[[\"No.\", \"Country\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Country'] if re.match('.*&.*', x)])>=1:\n",
    "        country_and_sep = df[df['Country'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Country\" entries with \"&\" separator (NOT split): {len(country_and_sep)}')\n",
    "            log.write(f'\\n{country_and_sep[[\"No.\", \"Country\"]].to_string(index=False)}')\n",
    "            log.write('\\n')        \n",
    "    \n",
    "    return country\n",
    "\n",
    "country = create_country_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615d59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: topic\n",
    "def create_topic_table(df, predefined_lists):\n",
    "    topic = df['Topics'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    topic = topic.explode(';')\n",
    "    topic = topic.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    topic.drop_duplicates(inplace=True)\n",
    "    topic = topic.sort_values(ascending=True).reset_index(drop=True)\n",
    "    topic = pd.DataFrame({\n",
    "              'topicID': [x for x in range(1,len(topic)+1)],\n",
    "              'topic': topic\n",
    "              })\n",
    "    topic = topic.dropna(subset=['topic']).reset_index(drop=True)\n",
    "    topic.to_csv('tables/topic.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: topic.csv created. {len(topic)} entries.\\n')\n",
    "\n",
    "    predefined_topics = list(predefined_lists[predefined_lists.columns[0]])\n",
    "    current_topics = list(topic['topic'])\n",
    "    if len(predefined_topics) != len(current_topics):\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---Topics not included in predefined list:\\n')\n",
    "        for topic_ in current_topics:\n",
    "            if topic_ not in predefined_topics:\n",
    "                with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "                    log.write(f'{topic_}\\n')      \n",
    "\n",
    "    df['Topics']=df['Topics'].apply(lambda x: x if isinstance(x, str) else '')                    \n",
    "                    \n",
    "    if len([x for x in df['Topics'] if re.match('.*,.*', x)])>=1:\n",
    "        topic_comma_sep = df[df['Topics'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Topics\" entries with \",\" separator (NOT split): {len(topic_comma_sep)}')\n",
    "            log.write(f'\\n{topic_comma_sep[[\"No.\", \"Topics\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Topics'] if re.match('.*;.*', x)])>=1:\n",
    "        topic_semicolon_sep = df[df['Topics'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Topics\" entries with \";\" separator (split): {len(topic_semicolon_sep)}')\n",
    "            #log.write(f'\\n{topic_semicolon_sep[[\"No.\", \"Topics\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Topics'] if re.match('.*&.*', x)])>=1:\n",
    "        topic_and_sep = df[df['Topics'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Topics\" entries with \"&\" separator (NOT split): {len(topic_and_sep)}')\n",
    "            #log.write(f'\\n{topic_and_sep[[\"No.\", \"Topics\"]].to_string(index=False)}')\n",
    "            log.write('\\n')        \n",
    "    \n",
    "    return topic\n",
    "\n",
    "topic = create_topic_table(df, predefined_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e435c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: target_group\n",
    "def create_target_group_table(df, predefined_lists):\n",
    "    target_group = df['Target group'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    target_group = target_group.explode(';')\n",
    "    target_group = target_group.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    target_group.drop_duplicates(inplace=True)\n",
    "    target_group = target_group.sort_values(ascending=True).reset_index(drop=True)\n",
    "    target_group = pd.DataFrame({\n",
    "              'targetID': [x for x in range(1,len(target_group)+1)],\n",
    "              'target_group': target_group\n",
    "              })\n",
    "    target_group = target_group.dropna(subset=['target_group']).reset_index(drop=True)\n",
    "    target_group.to_csv('tables/target_group.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: target_group.csv created. {len(target_group)} entries.\\n')\n",
    "\n",
    "    predefined_targets = list(predefined_lists[predefined_lists.columns[2]])\n",
    "    current_targets = list(target_group['target_group'])\n",
    "    if len(predefined_targets) != len(current_targets):\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---Target groups not included in predefined list:\\n')\n",
    "        for target in current_targets:\n",
    "            if target not in predefined_targets:\n",
    "                with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "                    log.write(f'{target}\\n')      \n",
    "\n",
    "    df['Target group']=df['Target group'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "                    \n",
    "    if len([x for x in df['Target group'] if re.match('.*,.*', x)])>=1:\n",
    "        targets_comma_sep = df[df['Target group'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Target group\" entries with \",\" separator (NOT split): {len(targets_comma_sep)}')\n",
    "            log.write(f'\\n{targets_comma_sep[[\"No.\", \"Target group\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Target group'] if re.match('.*;.*', x)])>=1:\n",
    "        targets_semicolon_sep = df[df['Target group'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Target group\" entries with \";\" separator (split): {len(targets_semicolon_sep)}')\n",
    "            #log.write(f'\\n{targets_semicolon_sep[[\"No.\", \"Target group\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Target group'] if re.match('.*&.*', x)])>=1:\n",
    "        targets_and_sep = df[df['Target group'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Target group\" entries with \"&\" separator (NOT split): {len(targets_and_sep)}')\n",
    "            log.write(f'\\n{targets_and_sep[[\"No.\", \"Target group\"]].to_string(index=False)}')\n",
    "            log.write('\\n')        \n",
    "    \n",
    "    return target_group\n",
    "\n",
    "target_group = create_target_group_table(df, predefined_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "194061d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: tech_type\n",
    "def create_tech_type_table(df, predefined_lists):\n",
    "    tech_type = df['(Tech) type'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    tech_type = tech_type.explode(';')\n",
    "    tech_type = tech_type.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    tech_type.drop_duplicates(inplace=True)\n",
    "    tech_type = tech_type.sort_values(ascending=True).reset_index(drop=True)\n",
    "    tech_type = pd.DataFrame({\n",
    "              'typeID': [x for x in range(1,len(tech_type)+1)],\n",
    "              'tech_type': tech_type\n",
    "              })\n",
    "    tech_type = tech_type.dropna(subset=['tech_type']).reset_index(drop=True)\n",
    "    tech_type.to_csv('tables/tech_type.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: tech_type.csv created. {len(tech_type)} entries.\\n')\n",
    "\n",
    "    predefined_types = list(predefined_lists[predefined_lists.columns[1]])\n",
    "    current_types = list(tech_type['tech_type'])\n",
    "    if len(predefined_types) != len(current_types):\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---(Tech) types not included in predefined list:\\n')\n",
    "        for type_ in current_types:\n",
    "            if type_ not in predefined_types:\n",
    "                with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "                    log.write(f'{type_}\\n')      \n",
    "\n",
    "    df['(Tech) type']=df['(Tech) type'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "                    \n",
    "    if len([x for x in df['(Tech) type'] if re.match('.*,.*', x)])>=1:\n",
    "        type_comma_sep = df[df['(Tech) type'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"(Tech) type\" entries with \",\" separator (NOT split): {len(type_comma_sep)}')\n",
    "            log.write(f'\\n{type_comma_sep[[\"No.\", \"(Tech) type\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['(Tech) type'] if re.match('.*;.*', x)])>=1:\n",
    "        type_semicolon_sep = df[df['(Tech) type'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"(Tech) type\" entries with \";\" separator (split): {len(type_semicolon_sep)}')\n",
    "            #log.write(f'\\n{type_semicolon_sep[[\"No.\", \"(Tech) type\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['(Tech) type'] if re.match('.*&.*', x)])>=1:\n",
    "        type_and_sep = df[df['(Tech) type'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"(Tech) type\" entries with \"&\" separator (NOT split): {len(type_and_sep)}')\n",
    "            log.write(f'\\n{type_and_sep[[\"No.\", \"(Tech) type\"]].to_string(index=False)}')\n",
    "            log.write('\\n')        \n",
    "    \n",
    "    return tech_type\n",
    "\n",
    "tech_type = create_tech_type_table(df, predefined_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097bfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe: tag\n",
    "def create_tag_table(df):\n",
    "    tag = df['Tags'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    tag = tag.explode(';')\n",
    "    tag = tag.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    tag.drop_duplicates(inplace=True)\n",
    "    tag = tag.sort_values(ascending=True).reset_index(drop=True)\n",
    "    tag = pd.DataFrame({\n",
    "              'tagID': [x for x in range(1,len(tag)+1)],\n",
    "              'tag': tag\n",
    "              })\n",
    "    tag = tag.dropna(subset=['tag']).reset_index(drop=True)\n",
    "    tag.to_csv('tables/tag.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: tag.csv created. {len(tag)} entries.\\n')\n",
    "    \n",
    "    df['Tags']=df['Tags'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "    \n",
    "    if len([x for x in df['Tags'] if re.match('.*,.*', x)])>=1:\n",
    "        tag_comma_sep = df[df['Tags'].str.contains(',')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Tag\" entries with \",\" separator (NOT split): {len(tag_comma_sep)}')\n",
    "            log.write(f'\\n{tag_comma_sep[[\"No.\", \"Tags\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Tags'] if re.match('.*;.*', x)])>=1:\n",
    "        tag_semicolon_sep = df[df['Tags'].str.contains(';')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Tag\" entries with \";\" separator (split): {len(tag_semicolon_sep)}')\n",
    "            #log.write(f'\\n{tag_semicolon_sep[[\"No.\", \"Tags\"]].to_string(index=False)}')\n",
    "            log.write('\\n')\n",
    "\n",
    "    if len([x for x in df['Tags'] if re.match('.*&.*', x)])>=1:\n",
    "        tag_and_sep = df[df['Tags'].str.contains('&')]\n",
    "        with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "            log.write(f'\\n---\"Tag\" entries with \"&\" separator (NOT split): {len(tag_and_sep)}')\n",
    "            log.write(f'\\n{tag_and_sep[[\"No.\", \"Tags\"]].to_string(index=False)}')\n",
    "            log.write('\\n')        \n",
    "    \n",
    "    return tag\n",
    "\n",
    "tag = create_tag_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6000403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\2853610813.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_organisation['organisationID'] = resource_X_organisation['organisationID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_organisation\n",
    "def create_resource_X_organisation_table(df, organisation):\n",
    "    organisation_mapping = dict(zip(organisation['organisation'], organisation['organisationID']))\n",
    "\n",
    "    resource_X_organisation = df[['No.', 'Organisation']]\n",
    "    resource_X_organisation.columns = ['resourceID', 'organisationID']\n",
    "    resource_X_organisation['organisationID'] = resource_X_organisation['organisationID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_organisation = resource_X_organisation.explode('organisationID')\n",
    "    resource_X_organisation['organisationID'] = resource_X_organisation['organisationID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_organisation['organisationID'] = resource_X_organisation['organisationID'].map(organisation_mapping)\n",
    "    resource_X_organisation.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    resource_X_organisation = resource_X_organisation.dropna(subset=['organisationID']).reset_index(drop=True)\n",
    "    resource_X_organisation['organisationID'] = resource_X_organisation['organisationID'].astype(int)\n",
    "    resource_X_organisation['linkID'] = [x for x in range(1,len(resource_X_organisation)+1)]\n",
    "    resource_X_organisation = resource_X_organisation[['linkID', 'resourceID', 'organisationID']]\n",
    "\n",
    "    resource_X_organisation.to_csv('tables/resource_X_organisation.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_organisation.csv created. {len(resource_X_organisation)} entries.\\n')\n",
    "    \n",
    "    return resource_X_organisation\n",
    "\n",
    "resource_X_organisation = create_resource_X_organisation_table(df, organisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe6f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\2884468188.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_country['countryID'] = resource_X_country['countryID'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_country\n",
    "def create_resource_X_country_table(df, country):\n",
    "    country_mapping = dict(zip(country['country'], country['countryID']))\n",
    "\n",
    "    resource_X_country = df[['No.', 'Country']]\n",
    "    resource_X_country.columns = ['resourceID', 'countryID']\n",
    "    resource_X_country['countryID'] = resource_X_country['countryID'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "    resource_X_country = resource_X_country.explode('countryID')\n",
    "    resource_X_country['countryID'] = resource_X_country['countryID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_country = resource_X_country.explode('countryID')\n",
    "    resource_X_country['countryID'] = resource_X_country['countryID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_country['countryID'] = resource_X_country['countryID'].map(country_mapping)\n",
    "    resource_X_country.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    resource_X_country = resource_X_country.dropna(subset=['countryID']).reset_index(drop=True)\n",
    "    resource_X_country['countryID'] = resource_X_country['countryID'].astype(int)\n",
    "    resource_X_country['linkID'] = [x for x in range(1,len(resource_X_country)+1)]\n",
    "    resource_X_country = resource_X_country[['linkID', 'resourceID', 'countryID']]\n",
    "\n",
    "    resource_X_country.to_csv('tables/resource_X_country.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_country.csv created. {len(resource_X_country)} entries.\\n')\n",
    "    \n",
    "    return resource_X_country\n",
    "\n",
    "resource_X_country = create_resource_X_country_table(df, country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f977a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\3213221762.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_topic['topicID'] = resource_X_topic['topicID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_topic\n",
    "def create_resource_X_topic_table(df, topic):\n",
    "    topic_mapping = dict(zip(topic['topic'], topic['topicID']))\n",
    "\n",
    "    resource_X_topic = df[['No.', 'Topics']]\n",
    "    resource_X_topic.columns = ['resourceID', 'topicID']\n",
    "    resource_X_topic['topicID'] = resource_X_topic['topicID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_topic = resource_X_topic.explode('topicID')\n",
    "    resource_X_topic['topicID'] = resource_X_topic['topicID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_topic['topicID'] = resource_X_topic['topicID'].map(topic_mapping)\n",
    "    resource_X_topic.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    resource_X_topic = resource_X_topic.dropna(subset=['topicID']).reset_index(drop=True)\n",
    "    resource_X_topic['topicID'] = resource_X_topic['topicID'].astype(int)\n",
    "    resource_X_topic['linkID'] = [x for x in range(1,len(resource_X_topic)+1)]\n",
    "    resource_X_topic = resource_X_topic[['linkID', 'resourceID', 'topicID']]\n",
    "\n",
    "    resource_X_topic.to_csv('tables/resource_X_topic.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_topic.csv created. {len(resource_X_topic)} entries.\\n')\n",
    "    \n",
    "    return resource_X_topic\n",
    "\n",
    "resource_X_topic = create_resource_X_topic_table(df, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba8f3b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\2554282233.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_target_group['targetID'] = resource_X_target_group['targetID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_target_group\n",
    "def create_resource_X_target_group_table(df, target_group):\n",
    "    targets_mapping = dict(zip(target_group['target_group'], target_group['targetID']))\n",
    "\n",
    "    resource_X_target_group = df[['No.', 'Target group']]\n",
    "    resource_X_target_group.columns = ['resourceID', 'targetID']\n",
    "    resource_X_target_group['targetID'] = resource_X_target_group['targetID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_target_group = resource_X_target_group.explode('targetID')\n",
    "    resource_X_target_group['targetID'] = resource_X_target_group['targetID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_target_group['targetID'] = resource_X_target_group['targetID'].map(targets_mapping)\n",
    "    resource_X_target_group.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    resource_X_target_group = resource_X_target_group.dropna(subset=['targetID']).reset_index(drop=True)    \n",
    "    resource_X_target_group['targetID'] = resource_X_target_group['targetID'].astype(int)\n",
    "    resource_X_target_group['linkID'] = [x for x in range(1,len(resource_X_target_group)+1)]\n",
    "    resource_X_target_group = resource_X_target_group[['linkID', 'resourceID', 'targetID']]\n",
    "\n",
    "    resource_X_target_group.to_csv('tables/resource_X_target_group.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_target_group.csv created. {len(resource_X_target_group)} entries.\\n')\n",
    "    \n",
    "    return resource_X_target_group\n",
    "\n",
    "resource_X_target_group = create_resource_X_target_group_table(df, target_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a337aa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\3041364726.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_tech_type['typeID'] = resource_X_tech_type['typeID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_tech_type\n",
    "def create_resource_X_tech_type_table(df, tech_type):\n",
    "    type_mapping = dict(zip(tech_type['tech_type'], tech_type['typeID']))\n",
    "\n",
    "    resource_X_tech_type = df[['No.', '(Tech) type']]\n",
    "    resource_X_tech_type.columns = ['resourceID', 'typeID']\n",
    "    resource_X_tech_type['typeID'] = resource_X_tech_type['typeID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_tech_type = resource_X_tech_type.explode('typeID')\n",
    "    resource_X_tech_type['typeID'] = resource_X_tech_type['typeID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_tech_type['typeID'] = resource_X_tech_type['typeID'].map(type_mapping)\n",
    "    resource_X_tech_type.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    resource_X_tech_type = resource_X_tech_type.dropna(subset=['typeID']).reset_index(drop=True)\n",
    "    resource_X_tech_type['typeID'] = resource_X_tech_type['typeID'].astype(int)\n",
    "    resource_X_tech_type['linkID'] = [x for x in range(1,len(resource_X_tech_type)+1)]\n",
    "    resource_X_tech_type = resource_X_tech_type[['linkID', 'resourceID', 'typeID']]\n",
    "\n",
    "    resource_X_tech_type.to_csv('tables/resource_X_tech_type.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_tech_type.csv created. {len(resource_X_tech_type)} entries.\\n')\n",
    "    \n",
    "    return resource_X_tech_type\n",
    "\n",
    "resource_X_tech_type = create_resource_X_tech_type_table(df, tech_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7f631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_9316\\2499756406.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resource_X_tag['tagID'] = resource_X_tag['tagID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe: resource_X_tag\n",
    "def create_resource_X_tag_table(df, tag):\n",
    "    tag_mapping = dict(zip(tag['tag'], tag['tagID']))\n",
    "\n",
    "    resource_X_tag = df[['No.', 'Tags']]\n",
    "    resource_X_tag.columns = ['resourceID', 'tagID']\n",
    "    resource_X_tag['tagID'] = resource_X_tag['tagID'].apply(lambda x: x.split(';') if isinstance(x, str) else x)\n",
    "    resource_X_tag = resource_X_tag.explode('tagID')\n",
    "    resource_X_tag['tagID'] = resource_X_tag['tagID'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    resource_X_tag['tagID'] = resource_X_tag['tagID'].map(tag_mapping)\n",
    "    resource_X_tag.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    resource_X_tag = resource_X_tag.dropna(subset=['tagID']).reset_index(drop=True)\n",
    "    resource_X_tag['tagID'] = resource_X_tag['tagID'].astype(int)\n",
    "    resource_X_tag['linkID'] = [x for x in range(1,len(resource_X_tag)+1)]\n",
    "    resource_X_tag = resource_X_tag[['linkID', 'resourceID', 'tagID']]\n",
    "        \n",
    "    resource_X_tag.to_csv('tables/resource_X_tag.csv', index=False)\n",
    "\n",
    "    with open(f'logs/{logfile_name}.txt', 'a') as log:\n",
    "        log.write(f'\\nTABLE CREATION: resource_X_tag.csv created. {len(resource_X_tag)} entries.\\n')\n",
    "    \n",
    "    return resource_X_tag\n",
    "\n",
    "resource_X_tag = create_resource_X_tag_table(df, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161fb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
