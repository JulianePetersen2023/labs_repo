{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda5eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import times\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240df4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d11360ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67f7facf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4293d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = t.drop(columns=['survived'])\n",
    "y = t['survived']\n",
    "\n",
    "def split_dataset(titanic_csv):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92bfbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be5d3df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass     sex   age  sibsp  parch      fare embarked   class    who  \\\n",
       "331       1    male  45.5      0      0   28.5000        S   First    man   \n",
       "733       2    male  23.0      0      0   13.0000        S  Second    man   \n",
       "382       3    male  32.0      0      0    7.9250        S   Third    man   \n",
       "704       3    male  26.0      1      0    7.8542        S   Third    man   \n",
       "813       3  female   6.0      4      2   31.2750        S   Third  child   \n",
       "..      ...     ...   ...    ...    ...       ...      ...     ...    ...   \n",
       "106       3  female  21.0      0      0    7.6500        S   Third  woman   \n",
       "270       1    male   NaN      0      0   31.0000        S   First    man   \n",
       "860       3    male  41.0      2      0   14.1083        S   Third    man   \n",
       "435       1  female  14.0      1      2  120.0000        S   First  child   \n",
       "102       1    male  21.0      0      1   77.2875        S   First    man   \n",
       "\n",
       "     adult_male deck  embark_town alive  alone  \n",
       "331        True    C  Southampton    no   True  \n",
       "733        True  NaN  Southampton    no   True  \n",
       "382        True  NaN  Southampton    no   True  \n",
       "704        True  NaN  Southampton    no  False  \n",
       "813       False  NaN  Southampton    no  False  \n",
       "..          ...  ...          ...   ...    ...  \n",
       "106       False  NaN  Southampton   yes   True  \n",
       "270        True  NaN  Southampton    no   True  \n",
       "860        True  NaN  Southampton    no  False  \n",
       "435       False    B  Southampton   yes  False  \n",
       "102        True    D  Southampton    no  False  \n",
       "\n",
       "[712 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d39a382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     pclass     sex   age  sibsp  parch      fare embarked   class    who  \\\n",
       " 331       1    male  45.5      0      0   28.5000        S   First    man   \n",
       " 733       2    male  23.0      0      0   13.0000        S  Second    man   \n",
       " 382       3    male  32.0      0      0    7.9250        S   Third    man   \n",
       " 704       3    male  26.0      1      0    7.8542        S   Third    man   \n",
       " 813       3  female   6.0      4      2   31.2750        S   Third  child   \n",
       " ..      ...     ...   ...    ...    ...       ...      ...     ...    ...   \n",
       " 106       3  female  21.0      0      0    7.6500        S   Third  woman   \n",
       " 270       1    male   NaN      0      0   31.0000        S   First    man   \n",
       " 860       3    male  41.0      2      0   14.1083        S   Third    man   \n",
       " 435       1  female  14.0      1      2  120.0000        S   First  child   \n",
       " 102       1    male  21.0      0      1   77.2875        S   First    man   \n",
       " \n",
       "      adult_male deck  embark_town alive  alone  \n",
       " 331        True    C  Southampton    no   True  \n",
       " 733        True  NaN  Southampton    no   True  \n",
       " 382        True  NaN  Southampton    no   True  \n",
       " 704        True  NaN  Southampton    no  False  \n",
       " 813       False  NaN  Southampton    no  False  \n",
       " ..          ...  ...          ...   ...    ...  \n",
       " 106       False  NaN  Southampton   yes   True  \n",
       " 270        True  NaN  Southampton    no   True  \n",
       " 860        True  NaN  Southampton    no  False  \n",
       " 435       False    B  Southampton   yes  False  \n",
       " 102        True    D  Southampton    no  False  \n",
       " \n",
       " [712 rows x 14 columns],\n",
       "      pclass     sex   age  sibsp  parch     fare embarked   class    who  \\\n",
       " 709       3    male   NaN      1      1  15.2458        C   Third    man   \n",
       " 439       2    male  31.0      0      0  10.5000        S  Second    man   \n",
       " 840       3    male  20.0      0      0   7.9250        S   Third    man   \n",
       " 720       2  female   6.0      0      1  33.0000        S  Second  child   \n",
       " 39        3  female  14.0      1      0  11.2417        C   Third  child   \n",
       " ..      ...     ...   ...    ...    ...      ...      ...     ...    ...   \n",
       " 433       3    male  17.0      0      0   7.1250        S   Third    man   \n",
       " 773       3    male   NaN      0      0   7.2250        C   Third    man   \n",
       " 25        3  female  38.0      1      5  31.3875        S   Third  woman   \n",
       " 84        2  female  17.0      0      0  10.5000        S  Second  woman   \n",
       " 10        3  female   4.0      1      1  16.7000        S   Third  child   \n",
       " \n",
       "      adult_male deck  embark_town alive  alone  \n",
       " 709        True  NaN    Cherbourg   yes  False  \n",
       " 439        True  NaN  Southampton    no   True  \n",
       " 840        True  NaN  Southampton    no   True  \n",
       " 720       False  NaN  Southampton   yes  False  \n",
       " 39        False  NaN    Cherbourg   yes  False  \n",
       " ..          ...  ...          ...   ...    ...  \n",
       " 433        True  NaN  Southampton    no   True  \n",
       " 773        True  NaN    Cherbourg    no   True  \n",
       " 25        False  NaN  Southampton   yes  False  \n",
       " 84        False  NaN  Southampton   yes   True  \n",
       " 10        False    G  Southampton   yes  False  \n",
       " \n",
       " [179 rows x 14 columns],\n",
       " 331    0\n",
       " 733    0\n",
       " 382    0\n",
       " 704    0\n",
       " 813    0\n",
       "       ..\n",
       " 106    1\n",
       " 270    0\n",
       " 860    0\n",
       " 435    1\n",
       " 102    0\n",
       " Name: survived, Length: 712, dtype: int64,\n",
       " 709    1\n",
       " 439    0\n",
       " 840    0\n",
       " 720    1\n",
       " 39     1\n",
       "       ..\n",
       " 433    0\n",
       " 773    0\n",
       " 25     1\n",
       " 84     1\n",
       " 10     1\n",
       " Name: survived, Length: 179, dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbebf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_values(X_train, X_test, column_names=[\"age\",\"embark_town\"], drop_columns=[\"deck\"]):\n",
    "    X_train[column_names] = X_train[column_names].fillna(X_train[column_names].median())\n",
    "    X_test[column_names] = X_test[column_names].fillna(X_test[column_names].median())\n",
    "    \n",
    "    X_train.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
    "    X_test.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
    "  \n",
    "    train_df = X_train\n",
    "    test_df = X_test\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "079021bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_8056\\1585665348.py:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  X_train[column_names] = X_train[column_names].fillna(X_train[column_names].median())\n",
      "C:\\Users\\Juliane\\AppData\\Local\\Temp\\ipykernel_8056\\1585665348.py:3: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  X_test[column_names] = X_test[column_names].fillna(X_test[column_names].median())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     pclass     sex   age  sibsp  parch      fare embarked   class    who  \\\n",
       " 331       1    male  45.5      0      0   28.5000        S   First    man   \n",
       " 733       2    male  23.0      0      0   13.0000        S  Second    man   \n",
       " 382       3    male  32.0      0      0    7.9250        S   Third    man   \n",
       " 704       3    male  26.0      1      0    7.8542        S   Third    man   \n",
       " 813       3  female   6.0      4      2   31.2750        S   Third  child   \n",
       " ..      ...     ...   ...    ...    ...       ...      ...     ...    ...   \n",
       " 106       3  female  21.0      0      0    7.6500        S   Third  woman   \n",
       " 270       1    male  28.0      0      0   31.0000        S   First    man   \n",
       " 860       3    male  41.0      2      0   14.1083        S   Third    man   \n",
       " 435       1  female  14.0      1      2  120.0000        S   First  child   \n",
       " 102       1    male  21.0      0      1   77.2875        S   First    man   \n",
       " \n",
       "      adult_male  embark_town alive  alone  \n",
       " 331        True  Southampton    no   True  \n",
       " 733        True  Southampton    no   True  \n",
       " 382        True  Southampton    no   True  \n",
       " 704        True  Southampton    no  False  \n",
       " 813       False  Southampton    no  False  \n",
       " ..          ...          ...   ...    ...  \n",
       " 106       False  Southampton   yes   True  \n",
       " 270        True  Southampton    no   True  \n",
       " 860        True  Southampton    no  False  \n",
       " 435       False  Southampton   yes  False  \n",
       " 102        True  Southampton    no  False  \n",
       " \n",
       " [712 rows x 13 columns],\n",
       "      pclass     sex   age  sibsp  parch     fare embarked   class    who  \\\n",
       " 709       3    male  29.0      1      1  15.2458        C   Third    man   \n",
       " 439       2    male  31.0      0      0  10.5000        S  Second    man   \n",
       " 840       3    male  20.0      0      0   7.9250        S   Third    man   \n",
       " 720       2  female   6.0      0      1  33.0000        S  Second  child   \n",
       " 39        3  female  14.0      1      0  11.2417        C   Third  child   \n",
       " ..      ...     ...   ...    ...    ...      ...      ...     ...    ...   \n",
       " 433       3    male  17.0      0      0   7.1250        S   Third    man   \n",
       " 773       3    male  29.0      0      0   7.2250        C   Third    man   \n",
       " 25        3  female  38.0      1      5  31.3875        S   Third  woman   \n",
       " 84        2  female  17.0      0      0  10.5000        S  Second  woman   \n",
       " 10        3  female   4.0      1      1  16.7000        S   Third  child   \n",
       " \n",
       "      adult_male  embark_town alive  alone  \n",
       " 709        True    Cherbourg   yes  False  \n",
       " 439        True  Southampton    no   True  \n",
       " 840        True  Southampton    no   True  \n",
       " 720       False  Southampton   yes  False  \n",
       " 39        False    Cherbourg   yes  False  \n",
       " ..          ...          ...   ...    ...  \n",
       " 433        True  Southampton    no   True  \n",
       " 773        True    Cherbourg    no   True  \n",
       " 25        False  Southampton   yes  False  \n",
       " 84        False  Southampton   yes   True  \n",
       " 10        False  Southampton   yes  False  \n",
       " \n",
       " [179 rows x 13 columns])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_missing_values(X_train, X_test, column_names=[\"age\",\"embark_town\"], drop_columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "457eba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       2\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    2\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56d86414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def feature_engineering(X_train, X_test, label_encoders={'Sex': \"LabelEncoder\", 'Embarked': \"OneHotEncoder\"},\n",
    "                        drop_cols=['SibSp', 'Parch', 'Sex', 'Embarked', 'PassengerId', 'Name', 'Ticket']):\n",
    "\n",
    "    for col, encoder_type in label_encoders.items():\n",
    "        if encoder_type == \"LabelEncoder\":\n",
    "            label_encoder = LabelEncoder()\n",
    "            X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "            X_test[col] = label_encoder.transform(X_test[col])\n",
    "        elif encoder_type == \"OneHotEncoder\":\n",
    "            X_train = pd.get_dummies(X_train, columns=[col], prefix=[col])\n",
    "            X_test = pd.get_dummies(X_test, columns=[col], prefix=[col])\n",
    "\n",
    "    # Create a new column 'TravelAlone' as a combination of 'SibSp' and 'Parch'\n",
    "    X_train['TravelAlone'] = (X_train['sibsp'] + X_train['parch']).apply(lambda x: 1 if x == 0 else 0)\n",
    "    X_test['TravelAlone'] = (X_test['sibsp'] + X_test['parch']).apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    X_train.drop(columns=drop_cols, inplace=True)\n",
    "    X_test.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5260eb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     pclass   age      fare   class    who  adult_male  embark_town alive  \\\n",
       " 331       1  45.5   28.5000   First    man        True  Southampton    no   \n",
       " 733       2  23.0   13.0000  Second    man        True  Southampton    no   \n",
       " 382       3  32.0    7.9250   Third    man        True  Southampton    no   \n",
       " 704       3  26.0    7.8542   Third    man        True  Southampton    no   \n",
       " 813       3   6.0   31.2750   Third  child       False  Southampton    no   \n",
       " ..      ...   ...       ...     ...    ...         ...          ...   ...   \n",
       " 106       3  21.0    7.6500   Third  woman       False  Southampton   yes   \n",
       " 270       1  28.0   31.0000   First    man        True  Southampton    no   \n",
       " 860       3  41.0   14.1083   Third    man        True  Southampton    no   \n",
       " 435       1  14.0  120.0000   First  child       False  Southampton   yes   \n",
       " 102       1  21.0   77.2875   First    man        True  Southampton    no   \n",
       " \n",
       "      alone  embarked_C  embarked_Q  embarked_S  TravelAlone  \n",
       " 331   True           0           0           1            1  \n",
       " 733   True           0           0           1            1  \n",
       " 382   True           0           0           1            1  \n",
       " 704  False           0           0           1            0  \n",
       " 813  False           0           0           1            0  \n",
       " ..     ...         ...         ...         ...          ...  \n",
       " 106   True           0           0           1            1  \n",
       " 270   True           0           0           1            1  \n",
       " 860  False           0           0           1            0  \n",
       " 435  False           0           0           1            0  \n",
       " 102  False           0           0           1            0  \n",
       " \n",
       " [712 rows x 13 columns],\n",
       "      pclass   age     fare   class    who  adult_male  embark_town alive  \\\n",
       " 709       3  29.0  15.2458   Third    man        True    Cherbourg   yes   \n",
       " 439       2  31.0  10.5000  Second    man        True  Southampton    no   \n",
       " 840       3  20.0   7.9250   Third    man        True  Southampton    no   \n",
       " 720       2   6.0  33.0000  Second  child       False  Southampton   yes   \n",
       " 39        3  14.0  11.2417   Third  child       False    Cherbourg   yes   \n",
       " ..      ...   ...      ...     ...    ...         ...          ...   ...   \n",
       " 433       3  17.0   7.1250   Third    man        True  Southampton    no   \n",
       " 773       3  29.0   7.2250   Third    man        True    Cherbourg    no   \n",
       " 25        3  38.0  31.3875   Third  woman       False  Southampton   yes   \n",
       " 84        2  17.0  10.5000  Second  woman       False  Southampton   yes   \n",
       " 10        3   4.0  16.7000   Third  child       False  Southampton   yes   \n",
       " \n",
       "      alone  embarked_C  embarked_Q  embarked_S  TravelAlone  \n",
       " 709  False           1           0           0            0  \n",
       " 439   True           0           0           1            1  \n",
       " 840   True           0           0           1            1  \n",
       " 720  False           0           0           1            0  \n",
       " 39   False           1           0           0            0  \n",
       " ..     ...         ...         ...         ...          ...  \n",
       " 433   True           0           0           1            1  \n",
       " 773   True           1           0           0            1  \n",
       " 25   False           0           0           1            0  \n",
       " 84    True           0           0           1            1  \n",
       " 10   False           0           0           1            0  \n",
       " \n",
       " [179 rows x 13 columns])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering(X_train, X_test, label_encoders={'sex': \"LabelEncoder\", 'embarked': \"OneHotEncoder\"},\n",
    "                        drop_cols=['sibsp', 'parch', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5256f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class',\n",
       "       'who', 'adult_male', 'embark_town', 'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02112041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    \"\"\"\n",
    "    Applies feature scaling on the input data using StandardScaler from scikit-learn.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pandas.DataFrame): Training data to scale, with feature engineering already done to it.\n",
    "    X_test (pandas.DataFrame): Test data to scale, with feature engineering already done to it.\n",
    "\n",
    "    Returns:\n",
    "    X_train_transf (numpy.ndarray): Scaled training data.\n",
    "    X_test_transf (numpy.ndarray): Scaled test data.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    st_scale = StandardScaler()\n",
    "    X_train_transf = st_scale.fit_transform(X_train)\n",
    "    X_test_transf = st_scale.transform(X_test)\n",
    "    return X_train_transf, X_test_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "225aefb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass            int64\n",
       "sex               int64\n",
       "age             float64\n",
       "sibsp             int64\n",
       "parch             int64\n",
       "fare            float64\n",
       "embarked         object\n",
       "class          category\n",
       "who              object\n",
       "adult_male         bool\n",
       "embark_town      object\n",
       "alive            object\n",
       "alone              bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b175275",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot cast object dtype to float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:551\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     new_cats \u001b[38;5;241m=\u001b[39m new_cats\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    552\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39m_na_value\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'First'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feature_scaling(X_train,X_test)\n",
      "Cell \u001b[1;32mIn[49], line 15\u001b[0m, in \u001b[0;36mfeature_scaling\u001b[1;34m(X_train, X_test)\u001b[0m\n\u001b[0;32m     13\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     14\u001b[0m st_scale \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 15\u001b[0m X_train_transf \u001b[38;5;241m=\u001b[39m st_scale\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m     16\u001b[0m X_test_transf \u001b[38;5;241m=\u001b[39m st_scale\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_transf, X_test_transf\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    862\u001b[0m     X,\n\u001b[0;32m    863\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    864\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    865\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    866\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:810\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    809\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[1;32m--> 810\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:227\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     values \u001b[38;5;241m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:562\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;167;01mTypeError\u001b[39;00m,  \u001b[38;5;66;03m# downstream error msg for CategoricalIndex is misleading\u001b[39;00m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[0;32m    560\u001b[0m     ):\n\u001b[0;32m    561\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dtype to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 562\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    564\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[0;32m    565\u001b[0m         new_cats, ensure_platform_int(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes), fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot cast object dtype to float64"
     ]
    }
   ],
   "source": [
    "feature_scaling(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ab8252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def log_reg_pred(X_train_transf, X_test_transf, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and evaluate a logistic regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    X_train_transf (array-like): Scaled training data.\n",
    "    X_test_transf (array-like): Scaled test data.\n",
    "    y_train (array-like): Labels for training data.\n",
    "    y_test (array-like): Labels for test data.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy score of the logistic regression classifier on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_transf, y_train)\n",
    "    y_pred = model.predict(X_test_transf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    " \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44c0b51e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_transf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m log_reg_pred(X_train_transf, X_test_transf, y_train, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_transf' is not defined"
     ]
    }
   ],
   "source": [
    "log_reg_pred(X_train_transf, X_test_transf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bb242",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def log_reg_pred(X_train_transf, X_test_transf, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and evaluate a logistic regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    X_train_transf (array-like): Scaled training data.\n",
    "    X_test_transf (array-like): Scaled test data.\n",
    "    y_train (array-like): Labels for training data.\n",
    "    y_test (array-like): Labels for test data.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy score of the logistic regression classifier on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the Logistic Regression model\n",
    "    logreg_model = LogisticRegression()\n",
    "\n",
    "    # Train the model on the scaled training data\n",
    "    logreg_model.fit(X_train_transf, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = logreg_model.predict(X_test_transf) # OR: y_pred = logreg.predict(X_test_transf)\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def rf_pred(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and evaluate a random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (array-like): Training data after feature engineering (data is not scaled).\n",
    "    X_test (array-like): Test data after feature engineering (data is not scaled).\n",
    "    y_train (array-like): Labels for training data.\n",
    "    y_test (array-like): Labels for test data.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy score of the random forest classifier on the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60b9b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def feature_selection_rf(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Perform feature selection using Random Forest Classifier.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): Array of training data features after feature engineering (data is not scaled).\n",
    "    X_test (numpy.ndarray): Array of test data features after feature engineering (data is not scaled).\n",
    "    y_train (array-like): Labels for training data.\n",
    "    y_test (array-like): Labels for test data.\n",
    "\n",
    "    Returns:\n",
    "    list: List containing 5 feature names which got the top 5 importance scores, in descending order\n",
    "    \"\"\"\n",
    "  \n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "    feature_importance_dict = dict(zip(range(len(feature_importances)), feature_importances))\n",
    "\n",
    "    top_5_features = sorted(feature_importance_dict, key=feature_importance_dict.get, reverse=True)[:5]\n",
    "\n",
    "    feature_names = [f\"Feature_{i}\" for i in top_5_features]\n",
    "\n",
    "    return feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def hyperparam_tuning_rf(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Tune hyperparameters for a Random Forest Classifier using grid search with cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): Array of training data features after feature engineering (data is not scaled).\n",
    "    X_test (numpy.ndarray): Array of test data features after feature engineering (data is not scaled).\n",
    "    y_train (numpy.ndarray): Array of training data labels.\n",
    "    y_test (numpy.ndarray): Array of test data labels.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (float, float) Returns a tuple containing the accuracy score of the best estimator on the training set and \n",
    "        the accuracy score of the predicted values on the testing set.\n",
    "    \"\"\"\n",
    " \n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "    y_train_pred = best_rf_classifier.predict(X_train)\n",
    "    y_test_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
